{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##*************************Task 1*********************#\n",
    "#\n",
    "#   (Class \"Critic\" should be a subclass of the class CriticBase. You must use the exact class name.)\n",
    "#   You should implement a multi-layer (2 or 3 layers) LSTM model in this class.\n",
    "#   The Model (the score function) takes a sequence of envents as input and outputs a score judging\n",
    "#   whether the piano music corresponding to the sequence is good music or bad music.\n",
    "#   A function to generate random music is provided in the \"midi2seq.py\".\n",
    "#   Use the function to create a collection of random piano plays as examples of bad music.\n",
    "#   Use the piano plays in the downloaded data as example of good music.\n",
    "#   (You don't need to use all the downloaded data. A sufficiently large subset will be enough.)\n",
    "#   Train the model in this class using both the good and the bad examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import numpy as np\n",
    "import os, sys, time, datetime, pickle, copy, random, glob\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from midi2seq import piano2seq, random_piano, process_midi_seq\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from model_base import ComposerBase, CriticBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before reshaping:- features, torch.Size([16136, 101]); labels, torch.Size([16136, 1])\n",
      "Size after reshaping:- features,torch.Size([16136, 101, 1]); labels, torch.Size([16136, 1])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "all_midis = glob.glob(f'./maestro-v1.0.0/**/*.midi')\n",
    "\n",
    "maxlen  = 100\n",
    "good_music_midi = process_midi_seq(all_midis=all_midis, n=10000, maxlen=maxlen)\n",
    "bad_music_midi = [random_piano(n=maxlen) for _ in range(len(all_midis))]\n",
    "bad_music_midi = process_midi_seq(all_midis=bad_music_midi, n=10000, maxlen=maxlen)\n",
    "\n",
    "good_music = torch.tensor(good_music_midi, dtype=torch.float32)\n",
    "bad_music = torch.tensor(bad_music_midi, dtype=torch.float32)\n",
    "\n",
    "good_labels = torch.ones((len(good_music), 1))\n",
    "bad_labels = torch.zeros((len(bad_music), 1))\n",
    "\n",
    "all_data = torch.cat([good_music, bad_music], dim=0)\n",
    "all_labels = torch.cat([good_labels, bad_labels], dim=0)\n",
    "\n",
    "features_train, features_test, label_train, label_test = train_test_split(\n",
    "                                                                            all_data, all_labels,\n",
    "                                                                                    test_size=0.2,\n",
    "                                                                                    shuffle=True)\n",
    "\n",
    "print(f\"Size before reshaping:- features, {features_train.shape}; labels, {label_train.shape}\")                                                                                    \n",
    "features_train = features_train.reshape((-1, features_train.shape[1], 1))\n",
    "features_test = features_test.reshape((-1, features_test.shape[1], 1))\n",
    "label_train = label_train.reshape((-1, 1))\n",
    "label_test = label_test.reshape((-1, 1))\n",
    "print(f\"Size after reshaping:- features,{features_train.shape}; labels, {label_train.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16139, 101, 1]),\n",
       " torch.Size([4035, 101, 1]),\n",
       " torch.Size([16139, 1]),\n",
       " torch.Size([4035, 1]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape, features_test.shape, label_train.shape, label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(labels):\n",
    "    converted = torch.zeros(labels.size(0), 2)\n",
    "    converted[labels.view(-1) == 1, 0] = 1\n",
    "    converted[labels.view(-1) == 0, 1] = 1\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train_ = convert_labels(label_train)\n",
    "label_test_ = convert_labels(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16139, 101, 1]),\n",
       " torch.Size([4035, 101, 1]),\n",
       " torch.Size([16139, 2]),\n",
       " torch.Size([4035, 2]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape, features_test.shape, label_train_.shape, label_test_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(features_train, label_train_)\n",
    "test_dataset = TensorDataset(features_test, label_test_)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 101, 1]) torch.Size([128, 2])\n"
     ]
    }
   ],
   "source": [
    "for _, batch in enumerate(train_loader):\n",
    "    print(batch[0].shape, batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module, CriticBase):\n",
    "    def __init__(self, input_dim, hidden_size, num_layers=3, n_classes=2):\n",
    "        super(Critic, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = n_classes\n",
    "        self.lstm = nn.LSTM(input_size = self.input_dim, hidden_size = self.hidden_size, num_layers = self.num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "        batch_size = x.size(0)\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        # LSTM forward pass\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        print(out.shape)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # linear layer\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    def score(self,x):\n",
    "        return(self.forward(x))\n",
    "\n",
    "    def train_model(self, dataloader, epochs=10, lr=0.0001):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "        self.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "        print(\"Start training\")\n",
    "        running_loss = 0.0\n",
    "        for epoch in range(epochs):\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.score(data)\n",
    "                loss = criterion(outputs, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                break\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "        print(\"Finished training\")\n",
    "\n",
    "        #torch.save(self.state_dict(), 'critic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 1/100, Loss: 0.6914892196655273\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 2/100, Loss: 0.690436065196991\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 3/100, Loss: 0.6933046579360962\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 4/100, Loss: 0.69371497631073\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 5/100, Loss: 0.6907191872596741\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 6/100, Loss: 0.6914653778076172\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 7/100, Loss: 0.6904364228248596\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 8/100, Loss: 0.6922365427017212\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 9/100, Loss: 0.6902852058410645\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 10/100, Loss: 0.689089298248291\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 11/100, Loss: 0.6884942054748535\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 12/100, Loss: 0.6930064558982849\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 13/100, Loss: 0.6890537738800049\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 14/100, Loss: 0.6877013444900513\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 15/100, Loss: 0.692158579826355\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 16/100, Loss: 0.6890537142753601\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 17/100, Loss: 0.6915029287338257\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 18/100, Loss: 0.6869091987609863\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 19/100, Loss: 0.6922129392623901\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 20/100, Loss: 0.6887197494506836\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 21/100, Loss: 0.6857444047927856\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 22/100, Loss: 0.690510630607605\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 23/100, Loss: 0.6893129944801331\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 24/100, Loss: 0.6910974979400635\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 25/100, Loss: 0.6888902187347412\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 26/100, Loss: 0.6877793669700623\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 27/100, Loss: 0.6912161707878113\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 28/100, Loss: 0.6867836713790894\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 29/100, Loss: 0.6881189346313477\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 30/100, Loss: 0.687195360660553\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 31/100, Loss: 0.6878582239151001\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 32/100, Loss: 0.6883261799812317\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 33/100, Loss: 0.6863604784011841\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 34/100, Loss: 0.6885276436805725\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 35/100, Loss: 0.687090277671814\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 36/100, Loss: 0.6835179924964905\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 37/100, Loss: 0.6862258911132812\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 38/100, Loss: 0.6862100958824158\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 39/100, Loss: 0.6871298551559448\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 40/100, Loss: 0.6840999126434326\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 41/100, Loss: 0.6863973140716553\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 42/100, Loss: 0.6850435137748718\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 43/100, Loss: 0.6846023201942444\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 44/100, Loss: 0.684907853603363\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 45/100, Loss: 0.6853890419006348\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 46/100, Loss: 0.683354377746582\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 47/100, Loss: 0.6840701103210449\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 48/100, Loss: 0.6826585531234741\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 49/100, Loss: 0.6834040880203247\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 50/100, Loss: 0.6804288029670715\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 51/100, Loss: 0.6802390813827515\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 52/100, Loss: 0.6800630688667297\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 53/100, Loss: 0.6797745227813721\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 54/100, Loss: 0.6830485463142395\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 55/100, Loss: 0.6799446940422058\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 56/100, Loss: 0.6804243326187134\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 57/100, Loss: 0.678540825843811\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 58/100, Loss: 0.6770936250686646\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 59/100, Loss: 0.6778022646903992\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 60/100, Loss: 0.6792372465133667\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 61/100, Loss: 0.6776963472366333\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 62/100, Loss: 0.6756117343902588\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 63/100, Loss: 0.6805557608604431\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 64/100, Loss: 0.6727105379104614\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 65/100, Loss: 0.674457311630249\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 66/100, Loss: 0.6731964945793152\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 67/100, Loss: 0.6685274839401245\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 68/100, Loss: 0.6719964742660522\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 69/100, Loss: 0.6675114631652832\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 70/100, Loss: 0.6688563227653503\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 71/100, Loss: 0.6697700023651123\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 72/100, Loss: 0.6698805689811707\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 73/100, Loss: 0.6688482165336609\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 74/100, Loss: 0.6641250848770142\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 75/100, Loss: 0.6624115705490112\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 76/100, Loss: 0.6620039939880371\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 77/100, Loss: 0.6583762168884277\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 78/100, Loss: 0.654747724533081\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 79/100, Loss: 0.6594272255897522\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 80/100, Loss: 0.6613608002662659\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 81/100, Loss: 0.6526193618774414\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 82/100, Loss: 0.6528090834617615\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 83/100, Loss: 0.6496708989143372\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 84/100, Loss: 0.6424499750137329\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 85/100, Loss: 0.6473499536514282\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 86/100, Loss: 0.6445590257644653\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 87/100, Loss: 0.6366916298866272\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 88/100, Loss: 0.6329934000968933\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 89/100, Loss: 0.6308419704437256\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 90/100, Loss: 0.6289281845092773\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 91/100, Loss: 0.6247614622116089\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 92/100, Loss: 0.6226783394813538\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 93/100, Loss: 0.6145626902580261\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 94/100, Loss: 0.6136407256126404\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 95/100, Loss: 0.602577805519104\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 96/100, Loss: 0.5986806154251099\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 97/100, Loss: 0.5782626867294312\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 98/100, Loss: 0.5853289365768433\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 99/100, Loss: 0.5780980587005615\n",
      "torch.Size([128, 101, 64])\n",
      "Epoch 100/100, Loss: 0.5565054416656494\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 64\n",
    "num_layers = 3\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "label_dim = 2\n",
    "\n",
    "# Initialize model, loss and optimizer\n",
    "critic_model = Critic(input_dim = input_dim, hidden_size=hidden_dim, n_classes=label_dim)\n",
    "critic_model.train_model(train_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge into Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidiDataProcessor:\n",
    "\n",
    "    def __init__(self, data_directory, maxlen=100, test_size=0.2, random_state=42, batch_size=32):\n",
    "        self.data_directory = data_directory\n",
    "        self.maxlen = maxlen\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __get__(self, idx):\n",
    "        return self.all_data[idx], self.all_labels[idx]\n",
    "\n",
    "    def prepare_data(self, is_scale=False):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "        all_midis = glob.glob(f'{self.data_directory}/maestro-v1.0.0/**/*.midi')\n",
    "\n",
    "        good_music_midi = process_midi_seq(all_midis=all_midis, datadir=self.data_directory, n=10000, maxlen=self.maxlen)\n",
    "        bad_music_midi = [random_piano(n=self.maxlen) for _ in range(len(all_midis))]\n",
    "        bad_music_midi = process_midi_seq(all_midis=bad_music_midi, datadir=self.data_directory, n=10000, maxlen=self.maxlen)\n",
    "\n",
    "        good_music = torch.tensor(good_music_midi, dtype=torch.float32)\n",
    "        bad_music = torch.tensor(bad_music_midi, dtype=torch.float32)\n",
    "\n",
    "        good_labels = torch.ones((len(good_music), 1))\n",
    "        bad_labels = torch.zeros((len(bad_music), 1))\n",
    "\n",
    "        self.all_data = torch.cat([good_music, bad_music], dim=0)\n",
    "        self.all_labels = torch.cat([good_labels, bad_labels], dim=0)\n",
    "\n",
    "        features_train, features_test, label_train, label_test = train_test_split(\n",
    "                                                                                    self.all_data, self.all_labels,\n",
    "                                                                                    test_size=self.test_size,\n",
    "                                                                                    random_state=self.random_state,\n",
    "                                                                                    shuffle=True)\n",
    "        features_train = features_train.reshape((-1, features_train.shape[1], 1))\n",
    "        features_test = features_test.reshape((-1, features_test.shape[1], 1))\n",
    "\n",
    "        label_train = label_train.reshape((-1, 1))\n",
    "        label_test = label_test.reshape((-1, 1))\n",
    "\n",
    "        def convert_labels(labels):\n",
    "            converted = torch.zeros(labels.size(0), 2)\n",
    "            converted[labels.view(-1) == 1, 0] = 1\n",
    "            converted[labels.view(-1) == 0, 1] = 1\n",
    "            return converted\n",
    "        \n",
    "        label_train = convert_labels(label_train)\n",
    "        label_test = convert_labels(label_test)\n",
    "        \n",
    "\n",
    "        features_train = torch.Tensor(features_train).to(device)\n",
    "        features_test = torch.Tensor(features_test).to(device)\n",
    "        label_train = torch.Tensor(label_train).to(device)\n",
    "        label_test = torch.Tensor(label_test).to(device)\n",
    "\n",
    "        train_dataset = TensorDataset(features_train, label_train)\n",
    "        test_dataset = TensorDataset(features_test, label_test)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, shuffle=True, batch_size=self.batch_size)\n",
    "        test_loader = DataLoader(test_dataset, shuffle=True, batch_size=self.batch_size)\n",
    "\n",
    "        return train_loader, test_loader\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MidiDataProcessor(data_directory={self.data_directory!r}, maxlen={self.maxlen}, test_size={self.test_size}, random_state={self.random_state}, batch_size={self.batch_size})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = MidiDataProcessor(data_directory='.')\n",
    "train_loader, test_loader = processor.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCritic(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_size=64, num_layers=3, n_classes=2):\n",
    "        super(LSTMCritic, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = n_classes\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "        self.lstm = nn.LSTM(input_size = self.input_dim, hidden_size = self.hidden_size, num_layers = self.num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n",
    "        # LSTM forward pass\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # linear layer\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMCritic(\n",
       "  (criterion): BCELoss()\n",
       "  (lstm): LSTM(1, 64, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_ = LSTMCritic(input_dim=1, hidden_size=64, num_layers=3, n_classes=2).to( device)\n",
    "model_ = torch.load('criticR111.pth')\n",
    "model_.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class Critic(CriticBase):\n",
    "    def __init__(self, load_trained=False):\n",
    "        '''\n",
    "        :param load_trained\n",
    "            If load_trained is True, load a trained model from a file.\n",
    "            Should include code to download the file from Google drive if necessary.\n",
    "            else, construct the model\n",
    "        '''    \n",
    "    \n",
    "        self.load_trained = load_trained\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "        self.model = LSTMCritic(input_dim=1, hidden_size=64, num_layers=3, n_classes=2).to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        if self.load_trained:\n",
    "            logging.info('load model from file ...')\n",
    "\n",
    "            self.model = torch.load('critic.pth')\n",
    "            self.model.eval()\n",
    "\n",
    "    def score(self, x):\n",
    "        '''\n",
    "        Compute the score of a music sequence\n",
    "        :param x: a music sequence\n",
    "        :return: the score between 0 and 1 that reflects the quality of the music: the closer to 1, the better\n",
    "        '''\n",
    "        with torch.set_grad_enabled(False):\n",
    "            logging.info('Compute score ...')\n",
    "        \n",
    "            outputs = self.model(x.to(self.device))\n",
    "            outputs = torch.argmax(outputs, dim=1)\n",
    "            outputs ^= 1 # index 0 is good and index 1 is bad \n",
    "                    \n",
    "        return outputs  \n",
    "\n",
    "    def train(self, x, epochs=10, lr=1e-5):\n",
    "        '''\n",
    "        Train the model on one batch of data\n",
    "        :param x: train data. For critic training, x will be a tuple of two tensors (data, label). expect a batch of dataloader\n",
    "        :return: (mean) loss of the model on the batch\n",
    "        '''\n",
    "            \n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "        logging.info('Start training ...')\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for epoch in range(epochs):\n",
    "            for idx, (feature, label) in enumerate(x):\n",
    "                feature, label = feature.to(self.device), label.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(feature)\n",
    "                loss = self.criterion(outputs, label)\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "        \n",
    "        logging.info(\"Finished training ...\")\n",
    "\n",
    "        torch.save(self.model, 'critic.pth')\n",
    "        \n",
    "        return total_loss/feature.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Start training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.6983073949813843\n",
      "Epoch 2/100, Loss: 0.24658606946468353\n",
      "Epoch 3/100, Loss: 0.06094246357679367\n",
      "Epoch 4/100, Loss: 0.037189848721027374\n",
      "Epoch 5/100, Loss: 0.06825444847345352\n",
      "Epoch 6/100, Loss: 0.030911851674318314\n",
      "Epoch 7/100, Loss: 0.029649732634425163\n",
      "Epoch 8/100, Loss: 0.07281500101089478\n",
      "Epoch 9/100, Loss: 0.007318323012441397\n",
      "Epoch 10/100, Loss: 0.006132175680249929\n",
      "Epoch 11/100, Loss: 0.008992061018943787\n",
      "Epoch 12/100, Loss: 0.004087052308022976\n",
      "Epoch 13/100, Loss: 0.005067975260317326\n",
      "Epoch 14/100, Loss: 0.0032931193709373474\n",
      "Epoch 15/100, Loss: 0.0028923728968948126\n",
      "Epoch 16/100, Loss: 0.0022897967137396336\n",
      "Epoch 17/100, Loss: 0.01976427435874939\n",
      "Epoch 18/100, Loss: 0.01067756675183773\n",
      "Epoch 19/100, Loss: 0.0037330188788473606\n",
      "Epoch 20/100, Loss: 0.0015168313402682543\n",
      "Epoch 21/100, Loss: 0.001699704211205244\n",
      "Epoch 22/100, Loss: 0.0021748384460806847\n",
      "Epoch 23/100, Loss: 0.00195964309386909\n",
      "Epoch 24/100, Loss: 0.002166065853089094\n",
      "Epoch 25/100, Loss: 0.0012154743308201432\n",
      "Epoch 26/100, Loss: 0.0009972633561119437\n",
      "Epoch 27/100, Loss: 0.0014962840359658003\n",
      "Epoch 28/100, Loss: 0.0011060452088713646\n",
      "Epoch 29/100, Loss: 0.003129423363134265\n",
      "Epoch 30/100, Loss: 0.0007276085671037436\n",
      "Epoch 31/100, Loss: 0.0007081010844558477\n",
      "Epoch 32/100, Loss: 0.03847796842455864\n",
      "Epoch 33/100, Loss: 0.003109220415353775\n",
      "Epoch 34/100, Loss: 0.0006208787090145051\n",
      "Epoch 35/100, Loss: 0.018774881958961487\n",
      "Epoch 36/100, Loss: 0.0012375640217214823\n",
      "Epoch 37/100, Loss: 0.15224359929561615\n",
      "Epoch 38/100, Loss: 0.012390036135911942\n",
      "Epoch 39/100, Loss: 0.001944411895237863\n",
      "Epoch 40/100, Loss: 0.0029004085808992386\n",
      "Epoch 41/100, Loss: 0.0009307052241638303\n",
      "Epoch 42/100, Loss: 0.0075102574191987514\n",
      "Epoch 43/100, Loss: 0.001969558885321021\n",
      "Epoch 44/100, Loss: 0.001072621438652277\n",
      "Epoch 45/100, Loss: 0.009201169945299625\n",
      "Epoch 46/100, Loss: 0.001549408072605729\n",
      "Epoch 47/100, Loss: 0.0003952379338443279\n",
      "Epoch 48/100, Loss: 0.0008399779326282442\n",
      "Epoch 49/100, Loss: 0.0003775689983740449\n",
      "Epoch 50/100, Loss: 0.0015906676417216659\n",
      "Epoch 51/100, Loss: 0.0045920428819954395\n",
      "Epoch 52/100, Loss: 0.01803591102361679\n",
      "Epoch 53/100, Loss: 0.00036885845474898815\n",
      "Epoch 54/100, Loss: 0.003188083413988352\n",
      "Epoch 55/100, Loss: 0.008306904695928097\n",
      "Epoch 56/100, Loss: 0.0003386504831723869\n",
      "Epoch 57/100, Loss: 0.00030646624509245157\n",
      "Epoch 58/100, Loss: 0.0004762838070746511\n",
      "Epoch 59/100, Loss: 0.0011629839427769184\n",
      "Epoch 60/100, Loss: 0.00025701243430376053\n",
      "Epoch 61/100, Loss: 0.0008029943564906716\n",
      "Epoch 62/100, Loss: 0.0003478498838376254\n",
      "Epoch 63/100, Loss: 0.0003121057234238833\n",
      "Epoch 64/100, Loss: 0.00024784053675830364\n",
      "Epoch 65/100, Loss: 0.0002453616471029818\n",
      "Epoch 66/100, Loss: 0.0007593796472065151\n",
      "Epoch 67/100, Loss: 0.0002159593132091686\n",
      "Epoch 68/100, Loss: 0.0024522256571799517\n",
      "Epoch 69/100, Loss: 0.00022184666886460036\n",
      "Epoch 70/100, Loss: 0.0017398209311068058\n",
      "Epoch 71/100, Loss: 0.00024126462813001126\n",
      "Epoch 72/100, Loss: 0.00026687292847782373\n",
      "Epoch 73/100, Loss: 0.005049528554081917\n",
      "Epoch 74/100, Loss: 0.0028322325088083744\n",
      "Epoch 75/100, Loss: 0.00026152265490964055\n",
      "Epoch 76/100, Loss: 0.00021424474834930152\n",
      "Epoch 77/100, Loss: 0.00020052136096637696\n",
      "Epoch 78/100, Loss: 0.0003713236073963344\n",
      "Epoch 79/100, Loss: 0.00041569568566046655\n",
      "Epoch 80/100, Loss: 0.0018338533118367195\n",
      "Epoch 81/100, Loss: 0.00021954681142233312\n",
      "Epoch 82/100, Loss: 0.00016185070853680372\n",
      "Epoch 83/100, Loss: 0.0007376136491075158\n",
      "Epoch 84/100, Loss: 0.0006922225002199411\n",
      "Epoch 85/100, Loss: 0.00038408985710702837\n",
      "Epoch 86/100, Loss: 0.00021777718211524189\n",
      "Epoch 87/100, Loss: 0.0003090346581302583\n",
      "Epoch 88/100, Loss: 0.0005501547129824758\n",
      "Epoch 89/100, Loss: 0.00030718237394466996\n",
      "Epoch 90/100, Loss: 0.00013963712262921035\n",
      "Epoch 91/100, Loss: 0.0012694038450717926\n",
      "Epoch 92/100, Loss: 0.007882731966674328\n",
      "Epoch 93/100, Loss: 0.03333599120378494\n",
      "Epoch 94/100, Loss: 0.0006340236868709326\n",
      "Epoch 95/100, Loss: 0.00021928513888269663\n",
      "Epoch 96/100, Loss: 0.00040821079164743423\n",
      "Epoch 97/100, Loss: 0.009310419671237469\n",
      "Epoch 98/100, Loss: 0.00032986418227665126\n",
      "Epoch 99/100, Loss: 0.011341502889990807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Finished training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.0001916042238008231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1482.1336252746405"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Critics = Critic(load_trained=False)\n",
    "\n",
    "Critics.train(train_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:load model from file ...\n",
      "INFO:Compute score ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1,  ..., 1, 1, 1], device='mps:0')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the load_trained model\n",
    "CriticsTest = Critic(load_trained=True)\n",
    "\n",
    "CriticsTest.score(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4036, 101, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5037165510406343"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "        \n",
    "torch_model = torch.load('critic.pth')\n",
    "torch_model.eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    x = features_test\n",
    "    print(x.shape)\n",
    "    outputs = torch_model(x.to(device))\n",
    "    outputs = torch.argmax(outputs, dim=1)\n",
    "    outputs ^= 1 # index 0 is good and index 1 is bad \n",
    "\n",
    "outputs == torch.flatten(label_test).to(device)\n",
    "\n",
    "arr = (outputs == torch.flatten(label_test).to(device)).to('cpu').numpy() #copy to cpu before convert to numpy\n",
    "final_test_acc = sum(arr)/len(arr)\n",
    "final_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Tuesday Oct 10, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import os, sys, time, datetime, pickle, copy, random, glob, logging\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from midi2seq import piano2seq, random_piano, process_midi_seq\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from model_base import ComposerBase, CriticBase\n",
    "\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training data\n",
    "class MidiDataProcessor:\n",
    "\n",
    "    def __init__(self, data_directory, maxlen=100, test_size=0.2, random_state=42, batch_size=32):\n",
    "        self.data_directory = data_directory\n",
    "        self.maxlen = maxlen\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __get__(self, idx):\n",
    "        return self.all_data[idx], self.all_labels[idx]\n",
    "\n",
    "    def prepare_data(self):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "        all_midis = glob.glob(f'{self.data_directory}/maestro-v1.0.0/**/*.midi')\n",
    "\n",
    "        good_music_midi = process_midi_seq(all_midis=all_midis, datadir=self.data_directory, n=10000, maxlen=self.maxlen)\n",
    "        bad_music_midi = [random_piano(n=self.maxlen) for _ in range(len(all_midis))]\n",
    "        bad_music_midi = process_midi_seq(all_midis=bad_music_midi, datadir=self.data_directory, n=10000, maxlen=self.maxlen)\n",
    "\n",
    "        good_music = torch.tensor(good_music_midi, dtype=torch.float32)\n",
    "        bad_music = torch.tensor(bad_music_midi, dtype=torch.float32)\n",
    "\n",
    "        good_labels = torch.ones((len(good_music), 1))\n",
    "        bad_labels = torch.zeros((len(bad_music), 1))\n",
    "\n",
    "        self.all_data = torch.cat([good_music, bad_music], dim=0)\n",
    "        self.all_labels = torch.cat([good_labels, bad_labels], dim=0)\n",
    "\n",
    "        features_train, features_test, label_train, label_test = train_test_split(\n",
    "                                                                                    self.all_data, self.all_labels,\n",
    "                                                                                    test_size=self.test_size,\n",
    "                                                                                    random_state=self.random_state,\n",
    "                                                                                    shuffle=True)\n",
    "        \n",
    "\n",
    "        def convert_labels(labels):\n",
    "            converted = torch.zeros(labels.size(0), 2)\n",
    "            converted[labels.view(-1) == 1, 0] = 1\n",
    "            converted[labels.view(-1) == 0, 1] = 1\n",
    "            return converted\n",
    "        \n",
    "        label_train = convert_labels(label_train)\n",
    "        label_test = convert_labels(label_test)\n",
    "\n",
    "        features_train = torch.Tensor(features_train).to(device)\n",
    "        features_test = torch.Tensor(features_test).to(device)\n",
    "\n",
    "        label_train = torch.Tensor(label_train).to(device)\n",
    "        label_test = torch.Tensor(label_test).to(device)\n",
    "\n",
    "        train_dataset = TensorDataset(features_train, label_train)\n",
    "        test_dataset = TensorDataset(features_test, label_test)\n",
    "\n",
    "        self.train_loader = DataLoader(train_dataset, shuffle=True, batch_size=self.batch_size)\n",
    "        self.test_loader = DataLoader(test_dataset, shuffle=True, batch_size=self.batch_size)\n",
    "\n",
    "        return self.train_loader, self.test_loader\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MidiDataProcessor(data_directory={self.data_directory!r}, maxlen={self.maxlen}, test_size={self.test_size}, random_state={self.random_state}, batch_size={self.batch_size}, train_loader size={len(self.train_loader.dataset)}, test_loader size={len(self.test_loader.dataset)})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_music_midi = process_midi_seq(datadir='.', n=10000, maxlen=100, rd_seed=1000)\n",
    "# good_music_midi.reshape((-1, good_music_midi.shape[1], 1)).min() # ((-1, features_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = MidiDataProcessor(data_directory='.')\n",
    "train_loader, test_loader = processor.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critic model\n",
    "\n",
    "class LSTMCritic(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim=128, num_layers=3, n_classes=2):\n",
    "        super(LSTMCritic, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.hidden_dim).to(self.device)\n",
    "        self.lstm = nn.LSTM(self.hidden_dim, self.hidden_dim, num_layers=self.num_layers, batch_first=True).to(self.device)\n",
    "        self.fc = nn.Linear(self.hidden_dim, n_classes).to(self.device)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding layer\n",
    "        x = self.embedding(x).to(self.device)\n",
    "        # LSTM forward pass\n",
    "        batch_size = x.size(0)\n",
    "        # Initialize hidden and cell states with zeros\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = lstm_out[:, -1, :]\n",
    "        # Linear layer\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critic model\n",
    "\n",
    "class LSTMCritic(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim=128, num_layers=3, n_classes=2):\n",
    "        super(LSTMCritic, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.hidden_dim).to(self.device)\n",
    "        self.lstm = nn.LSTM(self.hidden_dim, self.hidden_dim, num_layers=self.num_layers, batch_first=True).to(self.device)\n",
    "        self.fc = nn.Linear(self.hidden_dim, n_classes).to(self.device)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding layer\n",
    "        x = self.embedding(x).to(self.device)\n",
    "        # LSTM forward pass\n",
    "        batch_size = x.size(0)\n",
    "        # Initialize hidden and cell states with zeros\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = lstm_out[:, -1, :]\n",
    "        # Linear layer\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMCritic(vocab_size=2, hidden_dim=128, num_layers=3, n_classes=2)\n",
    "model = model.to(model.device)  # Move the model to the desired device\n",
    "\n",
    "lr = 0.001\n",
    "epochs = 100\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "logging.info('Start training ...')\n",
    "model.train()\n",
    "total_loss = 0\n",
    "for epoch in range(epochs):\n",
    "    for idx, (feature, label) in enumerate(train_loader):\n",
    "        feature, label = feature.to(device).long(), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(feature)\n",
    "        loss = criterion(outputs, label)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccumulationMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.value = 0.0\n",
    "        self.avg = 0.0\n",
    "        self.sum = 0\n",
    "        self.count = 0.0\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.value = value\n",
    "        self.sum += value * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        self.sqrt = self.value ** 0.5\n",
    "        self.rmse = self.avg ** 0.5\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance=5, min_delta=0):\n",
    "\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, train_loss, validation_loss):\n",
    "        if (validation_loss - train_loss) > self.min_delta:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.tolerance:  \n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critic class\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class Critic(CriticBase):\n",
    "    def __init__(self, load_trained=False):\n",
    "        '''\n",
    "        :param load_trained\n",
    "            If load_trained is True, load a trained model from a file.\n",
    "            Should include code to download the file from Google drive if necessary.\n",
    "            else, construct the model\n",
    "        '''    \n",
    "    \n",
    "        self.load_trained = load_trained\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "        self.model = LSTMCritic(vocab_size=500, hidden_dim=128, num_layers=3, n_classes=2).to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        if self.load_trained:\n",
    "            logging.info('load model from file ...')\n",
    "            gdd.download_file_from_google_drive(file_id='18YkTrsqa0dWCVC4PpE2_7q8nN3jxdzhD',\n",
    "                                    dest_path='./critic.pth',\n",
    "                                    unzip=True)\n",
    "            self.model = torch.load('critic.pth')\n",
    "            self.model.eval()\n",
    "\n",
    "    def score(self, x):\n",
    "        '''\n",
    "        Compute the score of a music sequence\n",
    "        :param x: a music sequence\n",
    "        :return: the score between 0 and 1 that reflects the quality of the music: the closer to 1, the better\n",
    "        '''\n",
    "        with torch.set_grad_enabled(False):\n",
    "            logging.info('Compute score ...')\n",
    "        \n",
    "            outputs = self.model(x.to(self.device))\n",
    "            outputs = torch.argmax(outputs, dim=1)\n",
    "            outputs ^= 1 # index 0 is good and index 1 is bad \n",
    "                    \n",
    "        return outputs  \n",
    "    \n",
    "    def validate(self, val_loader, model):\n",
    "        \"\"\"Evaluate the network on the entire validation set.\"\"\"\n",
    "\n",
    "        loss_accum = AccumulationMeter()\n",
    "        model.eval()\n",
    "        with torch.set_grad_enabled(False):\n",
    "\n",
    "            for i, (feature, label) in enumerate(val_loader):\n",
    "                feature, label = feature.to(self.device).long(), label.to(self.device)\n",
    "\n",
    "                outputs = self.model(feature)\n",
    "\n",
    "                loss = self.criterion(outputs, label)\n",
    "                loss_accum.update(loss.item(), label.size(0))\n",
    " \n",
    "\n",
    "        return loss_accum.rmse\n",
    "\n",
    "    def train(self, x, epochs=10, lr=1e-5):\n",
    "        '''\n",
    "        Train the model on one batch of data\n",
    "        :param x: train data. For critic training, x will be a tuple of two tensors (data, label). expect a batch of dataloader\n",
    "        :return: (mean) loss of the model on the batch\n",
    "        '''\n",
    "            \n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        loss_accum_train = AccumulationMeter()\n",
    "\n",
    "        # split data for K-fold cross validation to avoid overfitting\n",
    "        indices = list(range(len(x.dataset)))\n",
    "        kf = KFold(n_splits=5, shuffle=True)\n",
    "        cv_index = 0\n",
    "        index_list_train = []\n",
    "        index_list_valid = []\n",
    "        for train_indices, valid_indices in kf.split(indices):\n",
    "            index_list_train.append(train_indices)\n",
    "            index_list_valid.append(valid_indices)\n",
    "\n",
    "            train_sampler = SubsetRandomSampler(train_indices)\n",
    "            valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "\n",
    "            train_loader = DataLoader(x.dataset, batch_size=32,\n",
    "                                                       sampler=train_sampler,\n",
    "                                                       shuffle=False)\n",
    "            val_loader = DataLoader(x.dataset, batch_size=32,\n",
    "                                                     sampler=valid_sampler,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "            logging.info('Start training ...')\n",
    "            self.model.train()\n",
    "            early_stopping = EarlyStopping(tolerance=5, min_delta=10)\n",
    "            epoch_train_loss = []\n",
    "            epoch_validate_loss = []\n",
    "            for epoch in range(epochs):\n",
    "                for idx, (feature, label) in enumerate(train_loader):\n",
    "                    feature, label = feature.to(self.device).long(), label.to(self.device)\n",
    "\n",
    "                    outputs = self.model(feature)\n",
    "                    loss = self.criterion(outputs, label)\n",
    "                    #total_loss += loss.item()\n",
    "                    loss_accum_train.update(loss.item(), label.size(0))\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                # training loss\n",
    "                epoch_train_loss.append(loss_accum_train.avg)\n",
    "                \n",
    "                # validation loss\n",
    "                val_loss_avg = self.validate(val_loader, self.model)\n",
    "                epoch_validate_loss.append(val_loss_avg)\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {loss_accum_train.avg}, Val Loss: {val_loss_avg}\")\n",
    "\n",
    "                # early stopping\n",
    "                early_stopping(loss_accum_train.avg, val_loss_avg)\n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"We are at epoch:\", epoch)\n",
    "                    logging.info(\"Finished training ...Model saved\")\n",
    "                    torch.save(self.model, 'critic.pth') \n",
    "                    break\n",
    "        \n",
    "            cv_index += 1   # increment cv index\n",
    "        \n",
    "        return loss_accum_train.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Start training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.6917002614877992, Val Loss: 0.8294968625707562\n",
      "Epoch 2/100, Train Loss: 0.6691033990720859, Val Loss: 0.6616604525014153\n",
      "Epoch 3/100, Train Loss: 0.4930773457685144, Val Loss: 0.26094386346398285\n",
      "Epoch 4/100, Train Loss: 0.3847082929710066, Val Loss: 0.23794809452955532\n",
      "Epoch 5/100, Train Loss: 0.31714117089455124, Val Loss: 0.22171827681297912\n",
      "Epoch 6/100, Train Loss: 0.2714204840186782, Val Loss: 0.21149176010041\n",
      "Epoch 7/100, Train Loss: 0.23789563396844443, Val Loss: 0.20193328822853523\n",
      "Epoch 8/100, Train Loss: 0.212300402979822, Val Loss: 0.19181441002380759\n",
      "Epoch 9/100, Train Loss: 0.19182193755770774, Val Loss: 0.18392870302532874\n",
      "Epoch 10/100, Train Loss: 0.17528449735721488, Val Loss: 0.1728595726870176\n",
      "Epoch 11/100, Train Loss: 0.16144992917491977, Val Loss: 0.16551293523815055\n",
      "Epoch 12/100, Train Loss: 0.14978490334799432, Val Loss: 0.17387458425859195\n",
      "Epoch 13/100, Train Loss: 0.1397782665165306, Val Loss: 0.1522921362799879\n",
      "Epoch 14/100, Train Loss: 0.13101908989883354, Val Loss: 0.14779222730866953\n",
      "Epoch 15/100, Train Loss: 0.1232476236924989, Val Loss: 0.1339412005837835\n",
      "Epoch 16/100, Train Loss: 0.11630908345363397, Val Loss: 0.12996525162566763\n",
      "Epoch 17/100, Train Loss: 0.11010033440784725, Val Loss: 0.1201703737147789\n",
      "Epoch 18/100, Train Loss: 0.10452420996865414, Val Loss: 0.11728974912086665\n",
      "Epoch 19/100, Train Loss: 0.09949059642426045, Val Loss: 0.11304701393983078\n",
      "Epoch 20/100, Train Loss: 0.09488799520094143, Val Loss: 0.11572681927534259\n",
      "Epoch 21/100, Train Loss: 0.09065983088880028, Val Loss: 0.10880714357650118\n",
      "Epoch 22/100, Train Loss: 0.08683386238715188, Val Loss: 0.12004993783332675\n",
      "Epoch 23/100, Train Loss: 0.083273060267069, Val Loss: 0.10567809711793187\n",
      "Epoch 24/100, Train Loss: 0.08000446788828607, Val Loss: 0.10336665335738712\n",
      "Epoch 25/100, Train Loss: 0.07698288573097668, Val Loss: 0.09748242108190913\n",
      "Epoch 26/100, Train Loss: 0.07418666489568507, Val Loss: 0.10576087687070249\n",
      "Epoch 27/100, Train Loss: 0.07157707041860033, Val Loss: 0.08362821906074665\n",
      "Epoch 28/100, Train Loss: 0.06918325485147844, Val Loss: 0.07417557304935816\n",
      "Epoch 29/100, Train Loss: 0.0669030113680302, Val Loss: 0.08575485669207542\n",
      "Epoch 30/100, Train Loss: 0.06474711562391755, Val Loss: 0.0763357203754154\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gbemidebe/Documents/LSUCourses/Fall2023/CSC7343/homeworks/HW01/PianoGen/Critic.ipynb Cell 33\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gbemidebe/Documents/LSUCourses/Fall2023/CSC7343/homeworks/HW01/PianoGen/Critic.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m rt \u001b[39m=\u001b[39m Critic(load_trained\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gbemidebe/Documents/LSUCourses/Fall2023/CSC7343/homeworks/HW01/PianoGen/Critic.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m rt\u001b[39m.\u001b[39;49mtrain(train_loader, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32m/Users/gbemidebe/Documents/LSUCourses/Fall2023/CSC7343/homeworks/HW01/PianoGen/Critic.ipynb Cell 33\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbemidebe/Documents/LSUCourses/Fall2023/CSC7343/homeworks/HW01/PianoGen/Critic.ipynb#X44sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m epoch_validate_loss \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbemidebe/Documents/LSUCourses/Fall2023/CSC7343/homeworks/HW01/PianoGen/Critic.ipynb#X44sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gbemidebe/Documents/LSUCourses/Fall2023/CSC7343/homeworks/HW01/PianoGen/Critic.ipynb#X44sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     \u001b[39mfor\u001b[39;00m idx, (feature, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbemidebe/Documents/LSUCourses/Fall2023/CSC7343/homeworks/HW01/PianoGen/Critic.ipynb#X44sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m         feature, label \u001b[39m=\u001b[39m feature\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mlong(), label\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbemidebe/Documents/LSUCourses/Fall2023/CSC7343/homeworks/HW01/PianoGen/Critic.ipynb#X44sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(feature)\n",
      "File \u001b[0;32m~/miniconda3/envs/pianoGen/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pianoGen/lib/python3.8/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pianoGen/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/pianoGen/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/miniconda3/envs/pianoGen/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pianoGen/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pianoGen/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[1;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/miniconda3/envs/pianoGen/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rt = Critic(load_trained=False)\n",
    "rt.train(train_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12907"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pianoGen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
